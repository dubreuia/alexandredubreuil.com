<html lang="en">
<head>
  <title>Music Generation With Magenta.js - IRCAM demo 02</title>
  <meta content="text/html;charset=utf-8" http-equiv="Content-Type">
  <style>
    * {
      font-family: monospace;
    }

    canvas {
      width: 100%;
    }
  </style>
</head>
<body>
<div>
  <h1>Music Generation With Magenta.js - IRCAM demo 02</h1>
  <img src="../../common/img/magenta/logo-ircam.png" alt="Logo IRCAM">
  <p>
    <button disabled id="button-sample-musicae-melody">
      Sample MusicVAE melody sequence
    </button>
    <button disabled id="button-sample-gansynth-note">
      Sample GANSynth note as instrument
    </button>
    <button id="button-reload">
      Reload
    </button>
  </p>
  <p>
    <canvas style="width: 100%" id="canvas-musicvae-plot"></canvas>
  </p>
  <div id="container-plots">
  </div>
</div>
<script src="https://cdn.jsdelivr.net/npm/tone@13.8.25/build/Tone.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.5.2/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@magenta/music@^1.12.1/es6/core.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@magenta/music@^1.12.1/es6/gansynth.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@magenta/music@^1.12.1/es6/music_vae.js"></script>
<script>
  // Plots the spectrogram of the given channel
  // see music/demos/gansynth.ts:28 in magenta.js source code
  async function plotSpectra(spectra, channel) {
    const spectraPlot = tf.tidy(() => {
      // Slice a single example.
      let spectraPlot = tf.slice(spectra, [0, 0, 0, channel], [1, -1, -1, 1])
          .reshape([128, 1024]);
      // Scale to [0, 1].
      spectraPlot = tf.sub(spectraPlot, tf.min(spectraPlot));
      spectraPlot = tf.div(spectraPlot, tf.max(spectraPlot));
      return spectraPlot;
    });
    // Plot on canvas.
    const canvas = document.createElement("canvas");
    containerPlots.appendChild(canvas);
    await tf.browser.toPixels(spectraPlot, canvas);
    spectraPlot.dispose();
  }

  // Declares a new player that have 3 synths for the drum kit (only the
  // bass drum), the bass and the lead.
  class Player extends core.BasePlayer {

    constructor() {
      super();
      this.leadSynth = null;
    }

    // Plays the note at the proper time using tone.js
    playNote(time, note) {
      const synth = this.leadSynth;
      if (synth) {
        const frequency = new Tone.Frequency(note.pitch, "midi");
        const duration = note.endTime - note.startTime;
        synth.triggerAttackRelease(frequency, duration, time, 1);
      }
    }
  }
</script>
<script>
  // Get DOM elements
  const buttonSampleGanSynthNote = document.getElementById("button-sample-gansynth-note");
  const buttonSampleMusicVaeMelody = document.getElementById("button-sample-musicae-melody");
  const buttonReload = document.getElementById("button-reload");
  const containerPlots = document.getElementById("container-plots");
  const canvasMusicVaePlot = document.getElementById("canvas-musicvae-plot");

  // Add on click handler to call the MusicVAE sampling
  buttonSampleMusicVaeMelody.addEventListener("click", (event) => {
    sampleMusicVaeMelody();
    event.target.disabled = true;
    buttonSampleGanSynthNote.disabled = false;
  });

  // Add on click handler to call the GANSynth sampling
  buttonSampleGanSynthNote.addEventListener("click", () => {
    sampleGanNote();
  });

  // Add on click handler to call reloding
  buttonReload.addEventListener("click", () => {
    location.reload();
  });

  // Calls the initialization of MusicVAE and GanSynth
  try {
    Promise.all([startMusicVae(), startGanSynth()]);
  } catch (error) {
    console.error(error);
  }

  // Starts the MusicVAE model and initializes it. When finished, enables
  // the button to start the sampling
  async function startMusicVae() {
    const checkpointURL = "https://storage.googleapis.com/magentadata" +
        "/js/checkpoints/music_vae/mel_4bar_small_q2";
    const musicVae = new music_vae.MusicVAE(checkpointURL);
    await musicVae.initialize();
    window.musicVae = musicVae;
    buttonSampleMusicVaeMelody.disabled = false;
  }

  // Starts the GANSynth model and initializes it
  async function startGanSynth() {
    const checkpointURL = "https://storage.googleapis.com/magentadata" +
        "/js/checkpoints/gansynth/acoustic_only";
    const ganSynth = new gansynth.GANSynth(checkpointURL);
    await ganSynth.initialize();
    window.ganSynth = ganSynth
  }

  // Samples a melody from MusicVAE and plays it repeatedly at 120 QPM
  async function sampleMusicVaeMelody() {
    const samples = await window.musicVae.sample(1);
    const sample = samples[0];
    new core.PianoRollCanvasVisualizer(sample, canvasMusicVaePlot,
        {"pixelsPerTimeStep": 50});

    const player = new Player();
    Tone.Transport.loop = true;
    Tone.Transport.loopStart = 0;
    Tone.Transport.loopEnd = 8;
    player.start(sample, 120);
    window.player = player;
  }

  // Samples a single note of 4 seconds from GANSynth and plays it repeatedly
  async function sampleGanNote() {
    const lengthInSeconds = 4.0;
    const sampleRate = 16000;
    const length = lengthInSeconds * sampleRate;

    // The sampling returns a spectrogram, convert that to audio in
    // a tone.js buffer
    const specgrams = await ganSynth.randomSample(60);
    const audio = await ganSynth.specgramsToAudio(specgrams);
    const audioBuffer = Tone.context.createBuffer(1, length, sampleRate);
    audioBuffer.copyToChannel(audio, 0, 0);

    // Plays the sample using tone.js by using C4 as a base note,
    // since this is what we asked the model for (MIDI pitch 60).
    // If the sequence contains other notes, the pitch will be
    // changed automatically
    const volume = new Tone.Volume(-10);
    const instrument = new Tone.Sampler({"C4": audioBuffer});
    instrument.chain(volume, Tone.Master);
    window.player.leadSynth = instrument;
  }
</script>
</body>
</html>